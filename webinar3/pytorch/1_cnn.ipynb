{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6B8zAmXMzQa5"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/constantinpape/dl-teaching-resources/blob/main/exercises/classification/4_cnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xr3oCM0LzQa8"
   },
   "source": [
    "# CNN on CIFAR10\n",
    "\n",
    "In this exercise we will train our first convolutional neural network (CNN) on the cifar 10 dataset. Unlike the previous models we have used, logistic regression and multi-layer perceptrons, CNNs learn filters and classification jointly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pV1-kUaY-yqy"
   },
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zyXMvcuCzQbI"
   },
   "outputs": [],
   "source": [
    "# load tensorboard extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iX0lcNv2zQba"
   },
   "outputs": [],
   "source": [
    "# import torch and other libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import sklearn.metrics as metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import trange\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hLbdr5lyzQbk"
   },
   "outputs": [],
   "source": [
    "!pip install cifar2png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_adA5sMRzQb0"
   },
   "outputs": [],
   "source": [
    "# check if we have gpu support\n",
    "# colab offers free gpus, however they are not activated by default.\n",
    "# to activate the gpu, go to 'Runtime->Change runtime type'. \n",
    "# Then select 'GPU' in 'Hardware accelerator' and click 'Save'\n",
    "have_gpu = torch.cuda.is_available()\n",
    "# we need to define the device for torch, yadda yadda\n",
    "if have_gpu:\n",
    "    print(\"GPU is available\")\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    print(\"GPU is not available, training will run on the CPU\")\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LcngiR2HzQb_"
   },
   "outputs": [],
   "source": [
    "# run this in google colab to get the utils.py file\n",
    "!wget https://raw.githubusercontent.com/constantinpape/training-deep-learning-models-for-vison/master/day1/utils.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UxJnmv9OzQcK"
   },
   "outputs": [],
   "source": [
    "# we will reuse the training function, validation function and\n",
    "# data preparation from the previous notebook\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2s790zEKzQcV",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cifar_dir = './cifar10'\n",
    "!cifar2png cifar10 cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XK8eKTTSzQcb"
   },
   "outputs": [],
   "source": [
    "categories = os.listdir('./cifar10/train')\n",
    "categories.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_iVu6jS9zQcx"
   },
   "outputs": [],
   "source": [
    "# get training and validation data\n",
    "train_dataset, val_dataset = utils.make_cifar_datasets(cifar_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XaWkklrjzQci"
   },
   "source": [
    "## CNN\n",
    "\n",
    "Define the model architecture for our first CNN. The network is made up of the following components:\n",
    "- convolutional layers that convolve their input with a learnable filter, using less parameters than a fully connected layer while keeping spatial context\n",
    "- max pooling that halves the image size\n",
    "- fully connected layers at the end of the network to output a class prediction vector for the input\n",
    "\n",
    "Note that both convolutional layers and pooling operations change the spatial\n",
    "size of the data. You can find the formulas for this in the torch class descriptions: [nn.Conv2d](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#conv2d), [nn.MaxPool2d](https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html).\n",
    "See the comments in network definition below for an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jiMGapv9zQck"
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, n_classes):\n",
    "        super().__init__()\n",
    "        self.n_classes = n_classes\n",
    "\n",
    "        # the convolutions\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=12, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(in_channels=12, out_channels=24, kernel_size=3)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        # the fully connected part of the network\n",
    "        # after applying the convolutions and poolings, the tensor\n",
    "        # has the shape 24 x 6 x 6, see below\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(24 * 6 * 6, 120),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(120, 60),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(60, self.n_classes)\n",
    "        )\n",
    "        self.activation = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def apply_convs(self, x):\n",
    "      # input image has shape 3 x  32 x 32\n",
    "      x = self.pool(F.relu(self.conv1(x)))\n",
    "      # shape after conv: 12 x 28 x 28\n",
    "      # shape after pooling: 12 x 14 X 14\n",
    "      x = self.pool(F.relu(self.conv2(x)))\n",
    "      # shape after conv: 24 x 12 x 12\n",
    "      # shape after pooling: 24 x 6 x 6\n",
    "      return x\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.apply_convs(x)\n",
    "        x = x.view(-1, 24 * 6 * 6)\n",
    "        x = self.fc(x)\n",
    "        x = self.activation(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lXIWFz0AzQcr"
   },
   "outputs": [],
   "source": [
    "# instantiate the model\n",
    "model = CNN(n_classes=10)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OejyDJzOzQc7"
   },
   "outputs": [],
   "source": [
    "# instantiate loaders, loss, optimizer and tensorboard\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=25)\n",
    "\n",
    "optimizer = Adam(model.parameters(), lr=1.e-3)\n",
    "\n",
    "loss_function = nn.NLLLoss()\n",
    "loss_function.to(device)\n",
    "\n",
    "tb_logger = SummaryWriter('runs/log_cnn')\n",
    "%tensorboard --logdir runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ka_zkBLdzQdC"
   },
   "outputs": [],
   "source": [
    "n_epochs = 10\n",
    "for epoch in trange(n_epochs):\n",
    "    utils.train(model, train_loader, loss_function, optimizer,\n",
    "                device, epoch, tb_logger=tb_logger)\n",
    "    step = (epoch + 1) * len(train_loader)\n",
    "    utils.validate(model, val_loader, loss_function,\n",
    "                   device, step,\n",
    "                   tb_logger=tb_logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CAINshVEzQdJ"
   },
   "outputs": [],
   "source": [
    "# evaluate the model on test data\n",
    "test_dataset = utils.make_cifar_test_dataset(cifar_dir)\n",
    "test_loader = DataLoader(test_dataset, batch_size=25)\n",
    "predictions, labels = utils.validate(model, test_loader, loss_function,\n",
    "                                     device, step=0, tb_logger=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sDsUV2PmzQdX"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "print(\"Test accuracy:\")\n",
    "accuracy = metrics.accuracy_score(labels, predictions)\n",
    "print(accuracy)\n",
    "\n",
    "fig, ax = plt.subplots(1, figsize=(8, 8))\n",
    "utils.make_confusion_matrix(labels, predictions, categories, ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ApcetwEybANa"
   },
   "source": [
    "## Checkpoints and adaptive learning rate\n",
    "\n",
    "The model weights can be saved in order to load the model again and run prediction in a different application. If in addiation the optimizer state is saved the model training can also be resumed from the same state.\n",
    "\n",
    "Another important aspect of training neural networks is adapting the learning rate during training, which can increase model performance by converging to better optima. Here, we will condition the learning rate decrease on the validation accuracy using [torch.ReduceLROnPlateau](https://pytorch.org/docs/stable/optim.html#torch.optim.lr_scheduler.ReduceLROnPlateau)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jA0d4A6YbH0U"
   },
   "outputs": [],
   "source": [
    "# functions to save and load a checkpoint (= serialized model and optimizer state +\n",
    "# additional metadata)\n",
    "def save_checkpoint(model, optimizer, epoch, save_path):\n",
    "    # the state_dict of the model and the optimizer contain the current\n",
    "    # state of the model parameters and the optimizer\n",
    "    # it's only necessary to save the latter to resume training\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict()\n",
    "    }, save_path)\n",
    "\n",
    "\n",
    "def load_checkpoin(save_path, model, optimizer):\n",
    "    checkpoint = torch.load(save_path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict']) \n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    epoch = checkpoint['epoch']\n",
    "    return model, optimizer, epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K2ZIqf6SgiYk"
   },
   "outputs": [],
   "source": [
    "# instantiate loaders, loss, optimizer and tensorboard\n",
    "\n",
    "# instantiate the model\n",
    "model = CNN(10)\n",
    "model.to(device)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=25)\n",
    "\n",
    "optimizer = Adam(model.parameters(), lr=1.e-3)\n",
    "\n",
    "loss_function = nn.NLLLoss()\n",
    "loss_function.to(device)\n",
    "\n",
    "tb_logger = SummaryWriter(\"runs/log_cnn1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2H2UIpFwefDO"
   },
   "outputs": [],
   "source": [
    "n_epochs = 15\n",
    "\n",
    "# we use the best checkpoint as measured by the validation accuracy\n",
    "best_accuracy = 0.\n",
    "best_epoch = 0\n",
    "\n",
    "# monitor the validation accuracy and decrease the learning rate when\n",
    "# it starts to plateau\n",
    "# NOTE: it's usually better to choose a higher patience value than a single epoch,\n",
    "# we choose this value here in order to observe the changes when only training for 15 epochs\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "scheduler = ReduceLROnPlateau(optimizer,\n",
    "                              mode=\"max\",  # we evaluate based on accuracy, for which higher values are better\n",
    "                              factor=0.5,  # half the learning rate\n",
    "                              patience=1)  # number of epochs without improvement after which we reduce the lr\n",
    "\n",
    "for epoch in trange(n_epochs):\n",
    "    utils.train(model, train_loader, loss_function, optimizer,\n",
    "                device, epoch, tb_logger=tb_logger)\n",
    "    step = (epoch + 1) * len(train_loader)\n",
    "\n",
    "    pred, labels = utils.validate(model, val_loader, loss_function, device, step,\n",
    "                                  tb_logger=tb_logger)\n",
    "    val_accuracy = metrics.accuracy_score(labels, pred)\n",
    "    scheduler.step(val_accuracy)\n",
    "    \n",
    "    # otherwise, check if this is our best epoch\n",
    "    if val_accuracy > best_accuracy:\n",
    "        # if it is, save this check point\n",
    "        best_accuracy = val_accuracy\n",
    "        best_epoch = epoch\n",
    "        # print(\"Saving best checkpoint for epoch\", epoch)\n",
    "        save_checkpoint(model, optimizer, epoch, \"./best_checkpoint.tar\")\n",
    "\n",
    "print(\"The best checkpoint is number\", best_epoch) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W3ZWW3eTbary"
   },
   "outputs": [],
   "source": [
    "# load the model for the best checkpoint and evaluate it on the test data.\n",
    "# how do the results compare to before?\n",
    "# model, _, _ = load_checkpoint('./best_checkpoint.tar', model, optimizer)\n",
    "\n",
    "test_dataset = utils.make_cifar_test_dataset(cifar_dir)\n",
    "test_loader = DataLoader(test_dataset, batch_size=25)\n",
    "predictions, labels = utils.validate(model, test_loader, loss_function,\n",
    "                                     device, step=0, tb_logger=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wdm5a14w_sva"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "print(\"Test accuracy:\")\n",
    "accuracy = metrics.accuracy_score(labels, predictions)\n",
    "print(accuracy)\n",
    "\n",
    "fig, ax = plt.subplots(1, figsize=(8, 8))\n",
    "utils.make_confusion_matrix(labels, predictions, categories, ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rPHgUvO8R_PF"
   },
   "source": [
    "## Visualize learned filters\n",
    "\n",
    "The output of convolutional filters is still spatial, so it can be intepreted as images. Here, we inspect some of the filter responses of our network in order to visualize what features these filters pick up on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dMbOgxIWzQdd"
   },
   "outputs": [],
   "source": [
    "# apply the first convolutional filter of our model \n",
    "# to the first image from the training dataset\n",
    "model.to(torch.device('cpu'))\n",
    "model.eval()\n",
    "im = train_dataset[0][0][None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wJ7XwtAqEhtD"
   },
   "outputs": [],
   "source": [
    "conv1_response = model.conv1(im).detach().numpy()[0]\n",
    "print(conv1_response.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gw5wWxJ7HLhQ"
   },
   "outputs": [],
   "source": [
    "# visualize the filters in the first layer\n",
    "import matplotlib.pyplot as plt\n",
    "n_filters = 8\n",
    "fig, axes = plt.subplots(1, 1 + n_filters, figsize=(16, 4))\n",
    "im = im[0].numpy().transpose((1, 2, 0))\n",
    "axes[0].imshow(im)\n",
    "for chan_id in range(n_filters):\n",
    "    axes[chan_id + 1].imshow(conv1_response[chan_id], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uQUvUBL2zQdd"
   },
   "source": [
    "## Tasks and Questions\n",
    "\n",
    "Tasks:\n",
    "- Train another network with more convolutional layers / poolings and observe how the performance and training behaviour changes.\n",
    "- Visualize the convolutional filters for some of the deeper layers in your conv net.\n",
    "\n",
    "Questions:\n",
    "- How did the different models you have trained in this exercise perform? How do they compare to the non-convolutional models trained before?\n",
    "- How do you interpret the convolutional filters based on their visualisations? Can you see differences between the filters in the first and deeper layers?\n",
    "\n",
    "Advanced:\n",
    "- Construct a CNN that can be applied to input images of arbitrary size. Hint: Have a look at [nn.AdaptiveAveragePool2d](https://pytorch.org/docs/stable/generated/torch.nn.AdaptiveAvgPool2d.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "3_multi_layer_perceptron.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
