{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BaWMKwiySlW_"
   },
   "source": [
    "# Instance Segmentation with Stardist (3D)\n",
    "\n",
    "\n",
    "This exercise will demonstrate an approach (with stardist) to perform *instance segmentation* in 3D. *Instance segmentation* means, we aim to assign every pixel of the input image a unique label that signifies to which object it belongs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iOe5g3bvSuJu"
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "US4nq_f2Sf6a"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from tifffile import imread\n",
    "from csbdeep.utils import Path, download_and_extract_zip_file, normalize\n",
    "\n",
    "\n",
    "from stardist import relabel_image_stardist3D, Rays_GoldenSpiral, calculate_extents\n",
    "from stardist import fill_label_holes, random_label_cmap\n",
    "from stardist.matching import matching, matching_dataset\n",
    "from stardist.models import Config3D, StarDist3D, StarDistData3D\n",
    "\n",
    "np.random.seed(42)\n",
    "lbl_cmap = random_label_cmap()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sEU15_9zSf6d"
   },
   "source": [
    "# Data\n",
    "\n",
    "Similar as to the 2D case, we first have a look at how the training data for StarDist should look like and whether the annotated objects can be appropriately described by star-convex polyhedra.\n",
    "The training data that needs to be provided for StarDist consists of corresponding pairs of raw images and pixelwise annotated ground truth images (masks), where every pixel has a unique integer value indicating the object id (or 0 for background).\n",
    "\n",
    "For this demo we will download the file file demo3D.zip that contains synthetic train and test images with associated ground truth labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hnsO-gPRSf6e"
   },
   "outputs": [],
   "source": [
    "\n",
    "download_and_extract_zip_file(\n",
    "    url       = 'https://github.com/mpicbg-csbd/stardist/releases/download/0.3.0/demo3D.zip',\n",
    "    targetdir = 'data',\n",
    "    verbose   = 1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bKBWBJ-QSf6h"
   },
   "outputs": [],
   "source": [
    "fX = sorted(glob('data/train/images/*.tif'))\n",
    "fY = sorted(glob('data/train/masks/*.tif'))\n",
    "assert all(Path(x).name==Path(y).name for x,y in zip(fX,fY))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pTs--gG2Sf6j"
   },
   "source": [
    "Load only a small subset for display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NAoUNkj3Sf6k"
   },
   "outputs": [],
   "source": [
    "fX_small, fY_small = fX[:2], fY[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D0KznkMbSf6m"
   },
   "outputs": [],
   "source": [
    "X = list(map(imread,map(str,fX_small)))\n",
    "Y = list(map(imread,map(str,fY_small)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bx0HJj6vLMXd"
   },
   "outputs": [],
   "source": [
    "extents = calculate_extents(Y)\n",
    "anisotropy = tuple(np.max(extents) / extents)\n",
    "print('empirical anisotropy of labeled objects = %s' % str(anisotropy))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"><h2>Exercise</h2> \n",
    "    \n",
    "\n",
    "As for the 2D case, compute the same object level statistics for the training dataset, e.g. plot the histogram for the following properties:\n",
    "\n",
    "1) intensity range per raw image \n",
    "    \n",
    "2) number of objects per label images \n",
    "    \n",
    "3) average area of objects per label image     \n",
    "    \n",
    "Again `skimage.measure.regionprops` is your friend!\n",
    "        \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I6HBW-RsSf6n"
   },
   "source": [
    "## Example image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NyDOaaUtSf6o"
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "img, lbl = X[i], fill_label_holes(Y[i])\n",
    "assert img.ndim in (3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qurOFQSMSf6q"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,10))\n",
    "z = img.shape[0] // 2\n",
    "y = img.shape[1] // 2\n",
    "plt.subplot(121); plt.imshow(img[z],cmap='gray');   plt.axis('off'); plt.title('Raw image (XY slice)')\n",
    "plt.subplot(122); plt.imshow(lbl[z],cmap=lbl_cmap); plt.axis('off'); plt.title('GT labels (XY slice)')\n",
    "plt.figure(figsize=(16,10))\n",
    "plt.subplot(121); plt.imshow(img[:,y],cmap='gray');   plt.axis('off'); plt.title('Raw image (XZ slice)')\n",
    "plt.subplot(122); plt.imshow(lbl[:,y],cmap=lbl_cmap); plt.axis('off'); plt.title('GT labels (XZ slice)')\n",
    "None;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rB0MYufYSf6s"
   },
   "source": [
    "## Fitting ground-truth labels with star-convex polyhedra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RMc-Gl5lToSk"
   },
   "outputs": [],
   "source": [
    "def reconstruction_scores(n_rays, anisotropy):\n",
    "    scores = []\n",
    "    for r in tqdm(n_rays):\n",
    "        rays = Rays_GoldenSpiral(r, anisotropy=anisotropy)\n",
    "        Y_reconstructed = [relabel_image_stardist3D(lbl, rays) for lbl in Y]\n",
    "        mean_iou = matching_dataset(Y, Y_reconstructed, thresh=0, show_progress=False).mean_true_score\n",
    "        scores.append(mean_iou)\n",
    "    return scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T1sBKrtfLh5Q"
   },
   "outputs": [],
   "source": [
    "n_rays = [8, 16, 32, 64, 96, 128]\n",
    "scores_iso   = reconstruction_scores(n_rays, anisotropy=None)\n",
    "scores_aniso = reconstruction_scores(n_rays, anisotropy=anisotropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NtGL-kaOLtnk"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(n_rays, scores_iso,   'o-', label='Isotropic')\n",
    "plt.plot(n_rays, scores_aniso, 'o-', label='Anisotropic')\n",
    "plt.xlabel('Number of rays for star-convex polyhedra')\n",
    "plt.ylabel('Reconstruction score (mean intersection over union)')\n",
    "plt.legend()\n",
    "None;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HtVJWwb1T00w"
   },
   "source": [
    "### Example image reconstructed with various number of rays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qqnrU9DuT1i3"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2,3, figsize=(16,11))\n",
    "for a,r in zip(ax.flat,n_rays):\n",
    "    z = lbl.shape[0] // 2\n",
    "    rays = Rays_GoldenSpiral(r, anisotropy=anisotropy)\n",
    "    a.imshow(relabel_image_stardist3D(lbl, rays)[z], cmap=lbl_cmap, interpolation=\"none\")\n",
    "    a.set_title('Reconstructed (XY slice, %d rays)' % r)\n",
    "    a.axis('off')\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JwO371VFSf61"
   },
   "source": [
    "# Training \n",
    "\n",
    " Training data (for input `X` with associated label masks `Y`) can be provided via lists of numpy arrays, where each image can have a different size. Alternatively, a single numpy array can also be used if all images have the same size. Input images can either be three-dimensional (single-channel) or four-dimensional (multi-channel) arrays, where the channel axis comes last. Label images need to be integer-valued. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gZRk78lqSf61"
   },
   "outputs": [],
   "source": [
    "fX = sorted(glob('data/train/images/*.tif'))\n",
    "fY = sorted(glob('data/train/masks/*.tif'))\n",
    "assert all(Path(x).name==Path(y).name for x,y in zip(fX,fY))\n",
    "print(f\"{len(fX)} files found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TZ_rITSjSf63"
   },
   "outputs": [],
   "source": [
    "X = list(map(imread,map(str,tqdm(fX))))\n",
    "Y = list(map(imread,map(str,tqdm(fY))))\n",
    "n_channel = 1 if X[0].ndim == 3 else X[0].shape[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3nM21GHKSf66"
   },
   "source": [
    "Normalize images and fill small label holes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O0sSTDZ7Sf67"
   },
   "outputs": [],
   "source": [
    "axis_norm = (0,1,2)   # normalize channels independently\n",
    "# axis_norm = (0,1,2,3) # normalize channels jointly\n",
    "if n_channel > 1:\n",
    "    print(\"Normalizing image channels %s.\" % ('jointly' if axis_norm is None or 3 in axis_norm else 'independently'))\n",
    "    sys.stdout.flush()\n",
    "\n",
    "X = [normalize(x,1,99.8,axis=axis_norm) for x in tqdm(X)]\n",
    "Y = [fill_label_holes(y) for y in tqdm(Y)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EO3scWFrSf69"
   },
   "source": [
    "Split into train and validation datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B9PxV4maSf6-"
   },
   "outputs": [],
   "source": [
    "assert len(X) > 1, \"not enough training data\"\n",
    "rng = np.random.RandomState(42)\n",
    "ind = rng.permutation(len(X))\n",
    "n_val = max(1, int(round(0.15 * len(ind))))\n",
    "ind_train, ind_val = ind[:-n_val], ind[-n_val:]\n",
    "X_val, Y_val = [X[i] for i in ind_val]  , [Y[i] for i in ind_val]\n",
    "X_trn, Y_trn = [X[i] for i in ind_train], [Y[i] for i in ind_train] \n",
    "print('number of images: %3d' % len(X))\n",
    "print('- training:       %3d' % len(X_trn))\n",
    "print('- validation:     %3d' % len(X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sEQtdYiqMlmm"
   },
   "outputs": [],
   "source": [
    "def plot_img_label(img, lbl, img_title=\"image (XY slice)\", lbl_title=\"label (XY slice)\", z=None, **kwargs):\n",
    "    if z is None:\n",
    "        z = img.shape[0] // 2    \n",
    "    fig, (ai,al) = plt.subplots(1,2, figsize=(12,5), gridspec_kw=dict(width_ratios=(1.25,1)))\n",
    "    im = ai.imshow(img[z], cmap='gray', clim=(0,1))\n",
    "    ai.set_title(img_title)    \n",
    "    fig.colorbar(im, ax=ai)\n",
    "    al.imshow(lbl[z], cmap=lbl_cmap, interpolation=\"none\")\n",
    "    al.set_title(lbl_title)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "21L1LHeUSf7A"
   },
   "source": [
    "Training data consists of pairs of input image and label instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BNR7F44xSf7A"
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "img, lbl = X[i], Y[i]\n",
    "assert img.ndim in (3,4)\n",
    "img = img if img.ndim==3 else img[...,:3]\n",
    "plot_img_label(img,lbl)\n",
    "None;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sC1nVB4OSf7D"
   },
   "source": [
    "## Configuration\n",
    "\n",
    "A `StarDist3D` model is specified via a `Config3D` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cLOA--2hSf7D"
   },
   "outputs": [],
   "source": [
    "print(Config3D.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yrYJ9HCeM64I"
   },
   "outputs": [],
   "source": [
    "extents = calculate_extents(Y)\n",
    "anisotropy = tuple(np.max(extents) / extents)\n",
    "print('empirical anisotropy of labeled objects = %s' % str(anisotropy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VpJWGiR5Sf7I"
   },
   "outputs": [],
   "source": [
    "# 96 is a good default choice (see 1_data.ipynb)\n",
    "n_rays = 96\n",
    "\n",
    "\n",
    "# Predict on subsampled grid for increased efficiency and larger field of view\n",
    "grid = tuple(1 if a > 1.5 else 2 for a in anisotropy)\n",
    "\n",
    "# Use rays on a Fibonacci lattice adjusted for measured anisotropy of the training data\n",
    "rays = Rays_GoldenSpiral(n_rays, anisotropy=anisotropy)\n",
    "\n",
    "conf = Config3D (\n",
    "    rays             = rays,\n",
    "    grid             = grid,\n",
    "    anisotropy       = anisotropy,\n",
    "    n_channel_in     = n_channel,\n",
    "    # adjust for your data below (make patch size as large as possible)\n",
    "    train_patch_size = (48,96,96),\n",
    "    train_batch_size = 2,\n",
    ")\n",
    "print(conf)\n",
    "vars(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "noQaZKbNSf7N"
   },
   "outputs": [],
   "source": [
    "model = StarDist3D(conf, name='stardist', basedir='models')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D0bG10FUSf7P"
   },
   "source": [
    "Check if the neural network has a large enough field of view to see up to the boundary of most objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lgl5kG6GSf7Q"
   },
   "outputs": [],
   "source": [
    "median_size = calculate_extents(Y, np.median)\n",
    "fov = np.array(model._axes_tile_overlap('ZYX'))\n",
    "print(f\"median object size:      {median_size}\")\n",
    "print(f\"network field of view :  {fov}\")\n",
    "if any(median_size > fov):\n",
    "    print(\"WARNING: median object size larger than field of view of the neural network.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tzguGqwISf7T"
   },
   "source": [
    "## Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "09l9UNQ2Sf7T"
   },
   "source": [
    "\n",
    "You can define a function/callable that applies augmentation to each batch of the data generator.  \n",
    "We here use an `augmenter` that applies random rotations, flips, and intensity changes, which are typically sensible for  microscopy images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E4SYL3wXSf7U"
   },
   "outputs": [],
   "source": [
    "def random_fliprot(img, mask, axis=None): \n",
    "    if axis is None:\n",
    "        axis = tuple(range(mask.ndim))\n",
    "    axis = tuple(axis)\n",
    "            \n",
    "    assert img.ndim>=mask.ndim\n",
    "    perm = tuple(np.random.permutation(axis))\n",
    "    transpose_axis = np.arange(mask.ndim)\n",
    "    for a, p in zip(axis, perm):\n",
    "        transpose_axis[a] = p\n",
    "    transpose_axis = tuple(transpose_axis)\n",
    "    img = img.transpose(transpose_axis + tuple(range(mask.ndim, img.ndim))) \n",
    "    mask = mask.transpose(transpose_axis) \n",
    "    for ax in axis: \n",
    "        if np.random.rand() > 0.5:\n",
    "            img = np.flip(img, axis=ax)\n",
    "            mask = np.flip(mask, axis=ax)\n",
    "    return img, mask \n",
    "\n",
    "def random_intensity_change(img):\n",
    "    img = img*np.random.uniform(0.6,2) + np.random.uniform(-0.2,0.2)\n",
    "    return img\n",
    "\n",
    "def augmenter(x, y):\n",
    "    \"\"\"Augmentation of a single input/label image pair.\n",
    "    x is an input image\n",
    "    y is the corresponding ground-truth label image\n",
    "    \"\"\"\n",
    "    # Note that we only use fliprots along axis=(1,2), i.e. the yx axis \n",
    "    # as 3D microscopy acquisitions are usually not axially symmetric\n",
    "    x, y = random_fliprot(x, y, axis=(1,2))\n",
    "    x = random_intensity_change(x)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pLknrQ8n-eNu"
   },
   "outputs": [],
   "source": [
    "# plot some augmented examples\n",
    "img, lbl = X[0],Y[0]\n",
    "plot_img_label(img, lbl)\n",
    "for _ in range(3):\n",
    "    img_aug, lbl_aug = augmenter(img,lbl)\n",
    "    plot_img_label(img_aug, lbl_aug, img_title=\"image augmented (XY slice)\", lbl_title=\"label augmented (XY slice)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"><h2>Exercise</h2> \n",
    "    \n",
    "    \n",
    "As before, consider playing around with dedicated augmention packages (e.g. https://github.com/stardist/augmend, which comes as well with gpu accelerated tramsformations). \n",
    "       \n",
    "        \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VY7FSf_9-vJ0"
   },
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I9R4-D9W1TS9"
   },
   "source": [
    "Typically, a 3D model can take up to half a day to converge so we therefore set the number of `epochs` and `steps_per_epoch` to even smaller values than in the case of 2D... \n",
    "\n",
    "We recommend to monitor the progress during training with [TensorBoard](https://www.tensorflow.org/programmers_guide/summaries_and_tensorboard)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TvouFU_ASf7W"
   },
   "outputs": [],
   "source": [
    "model.train(X_trn, Y_trn, validation_data=(X_val,Y_val), augmenter=augmenter,\n",
    "                epochs=10, steps_per_epoch=30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7TZRSgHBSf7Y"
   },
   "source": [
    "## Threshold optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pxURfvjzSf7Y"
   },
   "source": [
    "While the default values for the probability and non-maximum suppression thresholds already yield good results in many cases, we still recommend to adapt the thresholds to your data. The optimized threshold values are saved to disk and will be automatically loaded with the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eyiOl6vFSf7Y",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if quick_demo:\n",
    "    # only use a single validation image for demo\n",
    "    model.optimize_thresholds(X_val[:1], Y_val[:1])\n",
    "else:\n",
    "    model.optimize_thresholds(X_val, Y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W9i_Uc0Vhkmo"
   },
   "source": [
    "# 3. Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aFqM_nfISf7b"
   },
   "source": [
    "We now load images from the sub-folder `test` that have not been used during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-F1dxPkjSf7c"
   },
   "outputs": [],
   "source": [
    "fX = sorted(glob('data/test/images/*.tif'))\n",
    "fY = sorted(glob('data/test/masks/*.tif'))\n",
    "assert all(Path(x).name==Path(y).name for x,y in zip(fX,fY))\n",
    "print(f\"{len(fX)} files found\")\n",
    "Xt = list(map(imread,map(str,tqdm(fX))))\n",
    "Yt = list(map(imread,map(str,tqdm(fY))))\n",
    "n_channel = 1 if Xt[0].ndim == 3 else Xt[0].shape[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZVZvImXHSf7j"
   },
   "source": [
    "## Prediction\n",
    "\n",
    "Make sure to normalize the input image beforehand or supply a `normalizer` to the prediction function.\n",
    "\n",
    "Calling `model.predict_instances` will\n",
    "- predict object probabilities and star-convex polygon distances (see `model.predict` if you want those)\n",
    "- perform non-maximum suppression (with overlap threshold `nms_thresh`) for polygons above object probability threshold `prob_thresh`.\n",
    "- render all remaining polygon instances in a label image\n",
    "- return the label instances image and also the details (coordinates, etc.) of all remaining polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zlC5U0QPSf7k"
   },
   "outputs": [],
   "source": [
    "i=0\n",
    "img = normalize(Xt[i], 1,99.8, axis=axis_norm)\n",
    "labels, details = model.predict_instances(img, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UsbTTP5bSf7m"
   },
   "outputs": [],
   "source": [
    "plot_img_label(img,Yt[i], lbl_title=\"label GT (XY slice)\")\n",
    "plot_img_label(img,labels, lbl_title=\"label Pred (XY slice)\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "iOe5g3bvSuJu",
    "sEU15_9zSf6d",
    "JwO371VFSf61",
    "W9i_Uc0Vhkmo"
   ],
   "name": "Copy of stardist_example_2D_colab.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
