{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Segmentation (2D)\n",
    "\n",
    "\n",
    "This exercise will demonstrate a very simple approach to perform *semantic segmentation* with convolutional neural networks. *Semantic segmentation* means, we aim to assign every pixel of the input image one of several different classes (background, cell interior, cell boundary) without distinguishing objects of the same class.\n",
    "\n",
    "![](_images/task_semantic.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.rcParams[\"image.interpolation\"] = None\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "from tifffile import imread\n",
    "from pathlib import Path\n",
    "import skimage\n",
    "from skimage.segmentation import find_boundaries\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "from csbdeep.internals.nets import common_unet, custom_unet\n",
    "from csbdeep.internals.blocks import unet_block, resnet_block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "\n",
    "First we download some sample images and corresponding masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from csbdeep.utils import download_and_extract_zip_file, normalize\n",
    "\n",
    "download_and_extract_zip_file(\n",
    "    url       = 'https://github.com/mpicbg-csbd/stardist/releases/download/0.1.0/dsb2018.zip',\n",
    "    targetdir = 'data',\n",
    "    verbose   = 1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we load the data, generate from the annotation masks background/foreground/cell border masks, and crop out a central patch (this is just for simplicity, as it makes our life a bit easier when all images have the same shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def crop(u,shape=(256,256)):\n",
    "    \"\"\"Crop central region of given shape\"\"\"\n",
    "    return u[tuple(slice((s-m)//2,(s-m)//2+m) for s,m in zip(u.shape,shape))]\n",
    "\n",
    "def to_3class_label(lbl, onehot=True):\n",
    "    \"\"\"Convert instance labeling to background/inner/outer mask\"\"\"\n",
    "    b = find_boundaries(lbl,mode='outer')\n",
    "    res = (lbl>0).astype(np.uint8)\n",
    "    res[b] = 2\n",
    "    if onehot:\n",
    "        res = tf.keras.utils.to_categorical(res,num_classes=3).reshape(lbl.shape+(3,))\n",
    "    return res\n",
    "\n",
    "# load and crop out central patch (for simplicity)\n",
    "X   = [normalize(crop(imread(x))) for x in sorted(glob('data/dsb2018/train/images/*.tif'))]\n",
    "Y   = [to_3class_label(crop(imread(y))) for y in sorted(glob('data/dsb2018/train/masks/*.tif'))]\n",
    "\n",
    "# convert to numpy arrays\n",
    "X, Y = np.expand_dims(np.stack(X),-1), np.stack(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot an example image\n",
    "i = 3\n",
    "fig, (a0,a1) = plt.subplots(1,2,figsize=(15,5))\n",
    "a0.imshow(X[i,...,0],cmap='gray');  \n",
    "a0.set_title('input image')\n",
    "a1.imshow(Y[i]);                    \n",
    "a1.set_title('segmentation mask')\n",
    "fig.suptitle(\"Example\")\n",
    "None;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"><h2>Exercise</h2> \n",
    "    \n",
    "\n",
    "1)  Plot some more images. What kind of data is shown? How variable is it? Do the segmentation masks look reasonable? \n",
    "        \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now split the training data into ~ 80/20 training and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from csbdeep.data import shuffle_inplace\n",
    "\n",
    "# shuffle data\n",
    "shuffle_inplace(X, Y, seed=0)\n",
    "\n",
    "# split into 80% training and 20% validation images\n",
    "n_val = len(X) // 5\n",
    "def split_train_val(a):\n",
    "    return a[:-n_val], a[-n_val:]\n",
    "X_train,       X_val       = split_train_val(X)\n",
    "Y_train,       Y_val       = split_train_val(Y)\n",
    "\n",
    "print(f'training   data: {len(X_train)} images and {len(Y_train)} masks')\n",
    "print(f'validation data: {len(X_val)} images and {len(Y_val)} masks')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a UNet \n",
    "\n",
    "We now will construct a very simple 3-class segmentation model, for which we will use a UNet \n",
    "\n",
    "<img width=400 src=\"https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/u-net-architecture.png\"></img>\n",
    "\n",
    "For the actual implementation, we will make use of the function `custom_unet` from `csbdeep.internals.nets`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from csbdeep.internals.nets import custom_unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = custom_unet(input_shape=(None,None,1), n_channel_out=3, kernel_size=(3,3), pool_size=(2,2), \n",
    "                    n_filter_base=32, last_activation='softmax')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"><h2>Exercise</h2> \n",
    "    \n",
    "\n",
    "1) What is the intuition about the gray \"skip connections\"? \n",
    "    \n",
    "2) Apply the (untrained) model on a example image (with `model.predict`). What is the output? How is it normalized?\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compiling the model \n",
    "\n",
    "We now will compile the model, i.e. deciding on a loss function and a optimizer.\n",
    "\n",
    "As we have a classification task with multiple output classes, we will use a simple `categorical_crossentropy` loss as loss function. Furthermore, `Adam` with the a learning rate on the order of `1e-4 - 1e-3` is a safe default (General reading tip: http://karpathy.github.io/2019/04/25/recipe/ :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=tf.keras.losses.categorical_crossentropy, optimizer=tf.keras.optimizers.Adam(learning_rate=3e-4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we train the model, we define some callbacks that will monitor the training loss etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from csbdeep.utils.tf import CARETensorBoardImage\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%d-%H:%M:%S\")\n",
    "logdir = Path(f'models/1_semantic_segmentation_2D/{timestamp}')\n",
    "logdir.mkdir(parents=True, exist_ok=True)\n",
    "callbacks = []\n",
    "callbacks.append(tf.keras.callbacks.TensorBoard(log_dir=logdir))\n",
    "callbacks.append(CARETensorBoardImage(model=model, data=(X_val,Y_val),\n",
    "                            log_dir=logdir/'images',\n",
    "                            n_images=3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ready to train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please someone let me know how to start tensorboard :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.fit(X_train, Y_train, validation_data=(X_val,Y_val),\n",
    "         epochs=100, callbacks=callbacks, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=1\n",
    "\n",
    "img  = X_val[i,..., 0]\n",
    "mask = Y_val[i]\n",
    "plt.imshow(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_pred = model.predict(img[np.newaxis,...,np.newaxis])[0]\n",
    "mask_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.measure import label\n",
    "\n",
    "# threshold inner (green) and find connected components\n",
    "lbl_pred = label(mask_pred[...,1] > 0.7)\n",
    "\n",
    "fig, ((a0,a1),(b0,b1)) = plt.subplots(2,2,figsize=(15,10))\n",
    "a0.imshow(img,cmap='gray');       \n",
    "a0.set_title('input image')\n",
    "a1.imshow(mask);                  \n",
    "a1.set_title('GT segmentation mask')\n",
    "b0.axis('off')\n",
    "b0.imshow(lbl_pred,cmap='tab20'); \n",
    "b0.set_title('label image (prediction)')\n",
    "b1.imshow(mask_pred);             \n",
    "b1.set_title('segmentation mask (prediction)')\n",
    "fig.suptitle(\"Example\")\n",
    "None;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"><h2>Exercise</h2> \n",
    "    \n",
    "\n",
    "Can you spot the label image mistakes? What could be the reason?\n",
    "    \n",
    " \n",
    "\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
