{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BaWMKwiySlW_"
   },
   "source": [
    "# Instance Segmentation with Stardist (2D)\n",
    "\n",
    "\n",
    "This exercise will demonstrate an approach (with stardist) to perform *instance segmentation*. *Instance segmentation* means, we aim to assign every pixel of the input image a unique label that signifies to which object it belongs.\n",
    "\n",
    "![](_images/task_instance.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iOe5g3bvSuJu"
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "US4nq_f2Sf6a"
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "import numpy as np\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from tqdm import tqdm\n",
    "from tifffile import imread\n",
    "from datetime import datetime\n",
    "from csbdeep.utils import Path, download_and_extract_zip_file, normalize\n",
    "\n",
    "from stardist.matching import matching_dataset\n",
    "from stardist import fill_label_holes, random_label_cmap, relabel_image_stardist, calculate_extents, gputools_available, _draw_polygons\n",
    "from stardist.models import Config2D, StarDist2D, StarDistData2D\n",
    "\n",
    "np.random.seed(42)\n",
    "lbl_cmap = random_label_cmap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#workaround for missing tensorboard\n",
    "!pip install tensorboard\n",
    "import os\n",
    "os.environ['TENSORBOARD_BINARY'] = os.path.expanduser('~/.local/bin/tensorboard')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sEU15_9zSf6d"
   },
   "source": [
    "# Data\n",
    "\n",
    "This section demonstrates how the training data for *StarDist* should look like and whether the annotated objects can be appropriately described by star-convex polygons. \n",
    "\n",
    "The training data that needs to be provided for StarDist consists of corresponding pairs of raw images and pixelwise annotated ground truth images (masks), where every pixel has a unique integer value indicating the object id (or 0 for background). \n",
    "\n",
    "For this demo we will download the file `dsb2018.zip` that contains the respective train and test images with associated ground truth labels as used in [our paper](https://arxiv.org/abs/1806.03535).\n",
    "They are a subset of the `stage1_train` images from the Kaggle 2018 Data Science Bowl, which are [available in full](https://data.broadinstitute.org/bbbc/BBBC038/) from the [Broad Bioimage Benchmark Collection](https://data.broadinstitute.org/bbbc/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hnsO-gPRSf6e"
   },
   "outputs": [],
   "source": [
    "download_and_extract_zip_file(\n",
    "    url       = 'https://github.com/mpicbg-csbd/stardist/releases/download/0.1.0/dsb2018.zip',\n",
    "    targetdir = 'data',\n",
    "    verbose   = 1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bKBWBJ-QSf6h"
   },
   "outputs": [],
   "source": [
    "fX = sorted(Path('data/dsb2018/train/images/').glob('*.tif'))\n",
    "fY = sorted(Path('data/dsb2018/train/masks').glob('*.tif'))\n",
    "print(f\"found {len(fX)} training images and {len(fY)} training masks\")\n",
    "assert all(Path(x).name==Path(y).name for x,y in zip(fX,fY))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pTs--gG2Sf6j"
   },
   "source": [
    "Load only a small subset for display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NAoUNkj3Sf6k"
   },
   "outputs": [],
   "source": [
    "fX_small, fY_small = fX[:10], fY[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D0KznkMbSf6m"
   },
   "outputs": [],
   "source": [
    "X_small = list(map(imread,map(str,fX_small)))\n",
    "Y_small = list(map(imread,map(str,fY_small)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I6HBW-RsSf6n"
   },
   "source": [
    "## Example image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NyDOaaUtSf6o"
   },
   "outputs": [],
   "source": [
    "i = min(4, len(X_small)-1)\n",
    "img, lbl = X_small[i], fill_label_holes(Y_small[i])\n",
    "assert img.ndim in (2,3)\n",
    "img = img if img.ndim==2 else img[...,:3]\n",
    "# assumed axes ordering of img and lbl is: YX(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qurOFQSMSf6q"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "plt.subplot(121); plt.imshow(img,cmap='gray');   plt.axis('off'); plt.title('Raw image')\n",
    "plt.subplot(122); plt.imshow(lbl,cmap=lbl_cmap, interpolation=\"nearest\"); plt.axis('off'); plt.title('GT labels (mask)')\n",
    "None;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"><h2>Exercise</h2> \n",
    "    \n",
    "\n",
    "A crucial part in any DL workflow is to get to know your data!\n",
    "    \n",
    "Please compute some object level statistics for the training dataset, e.g. plot the histogram for the following properties:\n",
    "\n",
    "1) intensity range per raw image \n",
    "    \n",
    "2) number of objects per label images \n",
    "    \n",
    "3) average area of objects per label image     \n",
    "    \n",
    "For the later part, `skimage.measure.regionprops` is your friend!\n",
    "        \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rB0MYufYSf6s"
   },
   "source": [
    "## Fitting ground-truth labels with star-convex polygons\n",
    "\n",
    "\n",
    "Before we train a stardist model, lets check whether its core assumption (roundish object) is appropriate. To that end, we will compute the best possible star-convex approximation for a certain number of rays and check whether it is reasonable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RMc-Gl5lToSk"
   },
   "outputs": [],
   "source": [
    "n_rays = [2**i for i in range(2,8)]\n",
    "print(n_rays)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HtVJWwb1T00w"
   },
   "source": [
    "### Example image reconstructed with various number of rays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qqnrU9DuT1i3"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2,3, figsize=(12,8))\n",
    "for a,r in zip(ax.flat,n_rays):\n",
    "    a.imshow(relabel_image_stardist(lbl, n_rays=r), cmap=lbl_cmap, interpolation=\"nearest\")\n",
    "    a.set_title('Reconstructed (%d rays)' % r)\n",
    "    a.axis('off')\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wNQweGV9TsRR"
   },
   "source": [
    "#### Mean IoU for different number of rays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NPZAInhNSf6t"
   },
   "outputs": [],
   "source": [
    "scores = []\n",
    "for r in tqdm(n_rays):\n",
    "    Y_reconstructed = [relabel_image_stardist(lbl, n_rays=r) for lbl in Y_small]\n",
    "    mean_iou = matching_dataset(Y_small, Y_reconstructed, thresh=0, show_progress=False).mean_true_score\n",
    "    scores.append(mean_iou)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0tBgKQijSf6u"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(n_rays, scores, 'o-')\n",
    "plt.xlabel('Number of rays for star-convex polygon')\n",
    "plt.ylabel('Reconstruction score (mean IoU)')\n",
    "plt.title(\"Mean IoU of ground truth reconstruction (should be > 0.8 for a reasonable number of rays)\")\n",
    "None;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JwO371VFSf61"
   },
   "source": [
    "# Training \n",
    "\n",
    "\n",
    "Training data (for input `X` with associated label masks `Y`) can be provided via lists of numpy arrays, where each image can have a different size. Alternatively, a single numpy array can also be used if all images have the same size.  \n",
    "Input images can either be two-dimensional (single-channel) or three-dimensional (multi-channel) arrays, where the channel axis comes last. Label images need to be integer-valued."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gZRk78lqSf61"
   },
   "outputs": [],
   "source": [
    "fX = sorted(Path('data/dsb2018/train/images/').glob('*.tif'))\n",
    "fY = sorted(Path('data/dsb2018/train/masks').glob('*.tif'))\n",
    "assert all(Path(x).name==Path(y).name for x,y in zip(fX,fY))\n",
    "print(f\"{len(fX)} files found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TZ_rITSjSf63"
   },
   "outputs": [],
   "source": [
    "X = list(map(imread,map(str,tqdm(fX))))\n",
    "Y = list(map(imread,map(str,tqdm(fY))))\n",
    "n_channel = 1 if X[0].ndim == 2 else X[0].shape[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3nM21GHKSf66"
   },
   "source": [
    "Normalize images and fill small label holes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O0sSTDZ7Sf67"
   },
   "outputs": [],
   "source": [
    "axis_norm = (0,1)   # normalize channels independently\n",
    "# axis_norm = (0,1,2) # normalize channels jointly\n",
    "if n_channel > 1:\n",
    "    print(\"Normalizing image channels %s.\" % ('jointly' if axis_norm is None or 2 in axis_norm else 'independently'))\n",
    "    sys.stdout.flush()\n",
    "\n",
    "X = [normalize(x,1,99.8,axis=axis_norm) for x in tqdm(X)]\n",
    "Y = [fill_label_holes(y) for y in tqdm(Y)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"><h2>Exercise</h2> \n",
    "    \n",
    "Can you guess what `normalize` does? Why don't we simply divide by the maximal possible pixel value (e.g. 65535 for 16 bit cameras) or the maximum of each image? \n",
    "        \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EO3scWFrSf69"
   },
   "source": [
    "Split into train and validation datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B9PxV4maSf6-"
   },
   "outputs": [],
   "source": [
    "assert len(X) > 1, \"not enough training data\"\n",
    "rng = np.random.RandomState(42)\n",
    "ind = rng.permutation(len(X))\n",
    "n_val = max(1, int(round(0.15 * len(ind))))\n",
    "ind_train, ind_val = ind[:-n_val], ind[-n_val:]\n",
    "X_val, Y_val = [X[i] for i in ind_val]  , [Y[i] for i in ind_val]\n",
    "X_trn, Y_trn = [X[i] for i in ind_train], [Y[i] for i in ind_train] \n",
    "print('number of images: %3d' % len(X))\n",
    "print('- training:       %3d' % len(X_trn))\n",
    "print('- validation:     %3d' % len(X_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "21L1LHeUSf7A"
   },
   "source": [
    "Training data consists of pairs of input image and label instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BNR7F44xSf7A"
   },
   "outputs": [],
   "source": [
    "i = min(9, len(X)-1)\n",
    "img, lbl = X[i], Y[i]\n",
    "assert img.ndim in (2,3)\n",
    "img = img if img.ndim==2 else img[...,:3]\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.subplot(121); plt.imshow(img,cmap='gray');   plt.axis('off'); plt.title('Raw image')\n",
    "plt.subplot(122); plt.imshow(lbl,cmap=lbl_cmap, interpolation=\"nearest\"); plt.axis('off'); plt.title('GT labels')\n",
    "None;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sC1nVB4OSf7D"
   },
   "source": [
    "## Configuration\n",
    "\n",
    "A `StarDist2D` model is specified via a `Config2D` object (essentially a `dict` of properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cLOA--2hSf7D"
   },
   "outputs": [],
   "source": [
    "print(Config2D.__doc__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will simply use 32 rays, which should be good enough. Additonally, we can set `grid=(2,2)` which only predicts every second pixel in teh final result (which vastly speeds everything up, and is reasonable if objects are larger than 2px)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VpJWGiR5Sf7I"
   },
   "outputs": [],
   "source": [
    "conf = Config2D (\n",
    "    n_rays       = 32,\n",
    "    grid         = (2,2),\n",
    "    n_channel_in = 1,\n",
    ")\n",
    "print(conf)\n",
    "vars(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "noQaZKbNSf7N"
   },
   "outputs": [],
   "source": [
    "timestamp = datetime.now().strftime(\"%d-%H:%M:%S\")\n",
    "\n",
    "model = StarDist2D(conf, name=f'stardist_{timestamp}', basedir='models/2_instance_segmentation_2D')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D0bG10FUSf7P"
   },
   "source": [
    "Check if the neural network has a large enough field of view to see up to the boundary of most objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lgl5kG6GSf7Q"
   },
   "outputs": [],
   "source": [
    "median_size = calculate_extents(list(Y), np.median)\n",
    "fov = np.array(model._axes_tile_overlap('YX'))\n",
    "\n",
    "if any(median_size > fov):\n",
    "    print(\"WARNING: median object size larger than field of view of the neural network.\")\n",
    "else:\n",
    "    print(f\"All good! (object sizes {median_size} fit into field of view {fov} of the neural network)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tzguGqwISf7T"
   },
   "source": [
    "## Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "09l9UNQ2Sf7T"
   },
   "source": [
    "\n",
    "You can define a function/callable that applies augmentation to each batch of the data generator.  \n",
    "We here use an `augmenter` that applies random rotations, flips, and intensity changes, which are typically sensible for (2D) microscopy images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E4SYL3wXSf7U"
   },
   "outputs": [],
   "source": [
    "def random_fliprot(img, mask): \n",
    "    axes = tuple(range(img.ndim)) \n",
    "    perm = np.random.permutation(axes)\n",
    "    img = img.transpose(perm) \n",
    "    mask = mask.transpose(perm) \n",
    "    for ax in axes: \n",
    "        if np.random.rand()>.5:\n",
    "            img = np.flip(img,axis = ax)\n",
    "            mask = np.flip(mask,axis = ax)\n",
    "    return img, mask \n",
    "\n",
    "def random_intensity_change(img):\n",
    "    img = img*np.random.uniform(0.6,2) + np.random.uniform(-.2,.2)\n",
    "    return img\n",
    "\n",
    "\n",
    "def augmenter(img,mask):\n",
    "    \"\"\"Augmentation for image,mask\"\"\"\n",
    "    img, mask = random_fliprot(img, mask)\n",
    "    img = random_intensity_change(img)\n",
    "    return img, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pLknrQ8n-eNu"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "plt.subplot(121); plt.imshow(img,cmap='gray', clim = (0,1));   plt.axis('off'); plt.title('Raw image')\n",
    "plt.subplot(122); plt.imshow(lbl,cmap=lbl_cmap, interpolation=\"nearest\"); plt.axis('off'); plt.title('GT labels (mask)')\n",
    "  \n",
    "for _ in range(4):\n",
    "    plt.figure(figsize=(8,5))\n",
    "    x,y = augmenter(img, lbl)\n",
    "    plt.subplot(121); plt.imshow(x,cmap='gray', clim = (0,1));   plt.axis('off'); plt.title('Augmented: Raw image')\n",
    "    plt.subplot(122); plt.imshow(y,cmap=lbl_cmap, interpolation=\"nearest\"); plt.axis('off'); plt.title('Augmented: GT labels (mask)')\n",
    "None;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"><h2>Exercise</h2> \n",
    "    \n",
    "\n",
    "1) Often times adding noise as additional augmentation leads to a robuster model. Can you incoporate such an augmentation in the `augmenter` function?\n",
    "    \n",
    "2) If you want to add even more augmentations (and see whether model performance changes), you can use the stardist `augmend` package: https://github.com/stardist/augmend . Feel free to play with it!\n",
    "        \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VY7FSf_9-vJ0"
   },
   "source": [
    "## Model Training\n",
    "\n",
    "Typically, a 2D model will be converged after .5-2hr training, which we wont do now. We therefore set the number of `epochs` and `steps_per_epoch` to smaller values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir=models/2_instance_segmentation_2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TvouFU_ASf7W"
   },
   "outputs": [],
   "source": [
    "model.train(X_trn, Y_trn, validation_data=(X_val,Y_val), augmenter=augmenter,\n",
    "                epochs=50, steps_per_epoch=50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7TZRSgHBSf7Y"
   },
   "source": [
    "## Threshold optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pxURfvjzSf7Y"
   },
   "source": [
    "While the default values for the probability and non-maximum suppression thresholds already yield good results in many cases, we still recommend to adapt the thresholds to your data. The optimized threshold values are saved to disk and will be automatically loaded with the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eyiOl6vFSf7Y"
   },
   "outputs": [],
   "source": [
    "model.optimize_thresholds(X_val[::5], Y_val[::5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W9i_Uc0Vhkmo"
   },
   "source": [
    "# 3. Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aFqM_nfISf7b"
   },
   "source": [
    "We now load images from the sub-folder `test` that have not been used during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-F1dxPkjSf7c"
   },
   "outputs": [],
   "source": [
    "fXt = sorted(Path('data/dsb2018/test/images/').glob('*.tif'))\n",
    "print(f\"{len(fXt)} files found\")\n",
    "Xt = list(map(imread,map(str,tqdm(fXt))))\n",
    "\n",
    "n_channel = 1 if Xt[0].ndim == 2 else Xt[0].shape[-1]\n",
    "axis_norm = (0,1)   # normalize channels independently\n",
    "# axis_norm = (0,1,2) # normalize channels jointly\n",
    "if n_channel > 1:\n",
    "    print(\"Normalizing image channels %s.\" % ('jointly' if axis_norm is None or 2 in axis_norm else 'independently'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZVZvImXHSf7j"
   },
   "source": [
    "## Prediction\n",
    "\n",
    "Make sure to normalize the input image beforehand or supply a `normalizer` to the prediction function.\n",
    "\n",
    "Calling `model.predict_instances` will\n",
    "- predict object probabilities and star-convex polygon distances (see `model.predict` if you want those)\n",
    "- perform non-maximum suppression (with overlap threshold `nms_thresh`) for polygons above object probability threshold `prob_thresh`.\n",
    "- render all remaining polygon instances in a label image\n",
    "- return the label instances image and also the details (coordinates, etc.) of all remaining polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zlC5U0QPSf7k"
   },
   "outputs": [],
   "source": [
    "img = normalize(Xt[16], 1,99.8, axis=axis_norm)\n",
    "labels, details = model.predict_instances(img, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UsbTTP5bSf7m"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(img if img.ndim==2 else img[...,:3], clim=(0,1), cmap='gray')\n",
    "plt.imshow(labels, cmap=lbl_cmap, interpolation=\"nearest\", alpha=0.5)\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TyLLSfoASf7o"
   },
   "source": [
    "## More example results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yx35cI3ASf7p"
   },
   "outputs": [],
   "source": [
    "def example(model, i, show_dist=True):\n",
    "    img = normalize(Xt[i], 1,99.8, axis=axis_norm)\n",
    "    labels, details = model.predict_instances(img)\n",
    "\n",
    "    plt.figure(figsize=(13,10))\n",
    "    img_show = img if img.ndim==2 else img[...,:3]\n",
    "    coord, points, prob = details['coord'], details['points'], details['prob']\n",
    "    plt.subplot(121); plt.imshow(img_show, cmap='gray'); plt.axis('off')\n",
    "    a = plt.axis()\n",
    "    _draw_polygons(coord, points, prob, show_dist=show_dist)\n",
    "    plt.axis(a)\n",
    "    plt.subplot(122); plt.imshow(img_show, cmap='gray'); plt.axis('off')\n",
    "    plt.imshow(labels, cmap=lbl_cmap, interpolation=\"nearest\", alpha=0.5)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zuB0Iq-5Sf7q"
   },
   "outputs": [],
   "source": [
    "example(model, 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1saqzu_CSf7s"
   },
   "outputs": [],
   "source": [
    "example(model, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ftpjFsbuSf7t"
   },
   "outputs": [],
   "source": [
    "example(model, 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dbD17JNyMrsw"
   },
   "source": [
    "## Evaluation and Detection Performance\n",
    "\n",
    "Besides the losses and metrics during training, we can also quantitatively evaluate the actual detection/segmentation performance on the validation data by considering objects in the ground truth to be correctly matched if there are predicted objects with overlap (here [intersection over union (IoU)](https://en.wikipedia.org/wiki/Jaccard_index)) beyond a chosen IoU threshold $\\tau$.\n",
    "\n",
    "The corresponding matching statistics (average overlap, accuracy, recall, precision, etc.) are typically of greater practical relevance than the losses/metrics computed during training (but harder to formulate as a loss function). \n",
    "The value of $\\tau$ can be between 0 (even slightly overlapping objects count as correctly predicted) and 1 (only pixel-perfectly overlapping objects count) and which $\\tau$ to use depends on the needed segmentation precision/application.\n",
    "\n",
    "Please see the Wikipedia page on [Sensitivity and specificity](https://en.wikipedia.org/wiki/Sensitivity_and_specificity) for definitions of the abbreviations used in the evaluation below. Note that `mean_true_score` refers to the average overlap (IoU) of all true positives (tp), i.e. correctly predicted objects in terms of the chosen overlap threshold.\n",
    "\n",
    "First predict the labels for all validation images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B0Ir85f2MrXp"
   },
   "outputs": [],
   "source": [
    "Y_val_pred = [model.predict_instances(x, n_tiles=model._guess_n_tiles(x), show_tile_progress=False)[0]\n",
    "              for x in tqdm(X_val)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yDgMAw5sM2cJ"
   },
   "source": [
    "Choose several IoU thresholds $\\tau$ that might be of interest and for each compute matching statistics for the validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ooj6e66eM10X"
   },
   "outputs": [],
   "source": [
    "taus = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "stats = [matching_dataset(Y_val, Y_val_pred, thresh=t, show_progress=False) for t in tqdm(taus)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-WZVsRcyM6Eo"
   },
   "source": [
    "Example: Print all available matching statistics for $\\tau=0.5$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Kovhf4reM8bs"
   },
   "outputs": [],
   "source": [
    "stats[taus.index(0.5)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zldGIgddNAmH"
   },
   "source": [
    "Plot the matching statistics and the number of true/false positives/negatives as a function of the IoU threshold $\\tau$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6xjwSMeZNAFk"
   },
   "outputs": [],
   "source": [
    "fig, (ax1,ax2) = plt.subplots(1,2, figsize=(15,5))\n",
    "\n",
    "for m in ('precision', 'recall', 'accuracy', 'f1', 'mean_true_score'):\n",
    "    ax1.plot(taus, [s._asdict()[m] for s in stats], '.-', lw=2, label=m)\n",
    "ax1.set_xlabel(r'IoU threshold $\\tau$')\n",
    "ax1.set_ylabel('Metric value')\n",
    "ax1.grid()\n",
    "ax1.legend()\n",
    "\n",
    "for m in ('fp', 'tp', 'fn'):\n",
    "    ax2.plot(taus, [s._asdict()[m] for s in stats], '.-', lw=2, label=m)\n",
    "ax2.set_xlabel(r'IoU threshold $\\tau$')\n",
    "ax2.set_ylabel('Number #')\n",
    "ax2.grid()\n",
    "ax2.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"><h2>Exercise</h2> \n",
    "    \n",
    "1) Rerun the training while using only few (e.g. 10) images. How much does accuracy drop? How low can you go?  \n",
    "        \n",
    "2) If you want, you can install the stardist napari plugin (https://github.com/stardist/stardist-napari) on your local machine, transfer the model folder, and apply it to images that you have.\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "iOe5g3bvSuJu",
    "sEU15_9zSf6d",
    "JwO371VFSf61",
    "W9i_Uc0Vhkmo"
   ],
   "name": "Copy of stardist_example_2D_colab.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "DL for Image Analysis 2022 (Keras)",
   "language": "python",
   "name": "dl-mw-py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
