{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cxJNtcLHyxK7"
   },
   "source": [
    "# U-Net for myelin segmentation\n",
    "\n",
    "Simple unet approach for myelin segmentaiton, based on simplified version of pytorch unet exercise from webinar 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d5CNxOpgx-ey"
   },
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from functools import partial\n",
    "from glob import glob\n",
    "\n",
    "import imageio\n",
    "import napari\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Check the data\n",
    "\n",
    "Check that the data is correct in napari."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO adapt this to where you have stored the data\n",
    "root_dir = os.path.expanduser(\"~/Work/data/dl-course-2022/prepared_data_v1\")\n",
    "\n",
    "# select all train images and labels using glob\n",
    "# we need to sort afterwards to make sure that the order is the same, because glob does not sort the filepaths\n",
    "train_images = glob(os.path.join(root_dir, \"train\", \"images\", \"*tif\"))\n",
    "train_images.sort()\n",
    "train_labels = glob(os.path.join(root_dir, \"train\", \"labels\", \"*.tif\"))\n",
    "train_labels.sort()\n",
    "assert len(train_images) == len(train_labels)\n",
    "\n",
    "# load images and labels into memory\n",
    "train_images = [imageio.imread(im) for im in train_images]\n",
    "train_labels = [imageio.imread(lab) for lab in train_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# display images and labels in napari\n",
    "def view_image_and_labels(image, label):\n",
    "    v = napari.Viewer()\n",
    "    v.add_image(image)\n",
    "    v.add_labels(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# this will display all images and labels at once, quickly have a look that they match!\n",
    "for image, label in zip(train_images, train_labels):\n",
    "    view_image_and_labels(image, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Implement the training pipeline and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# normalize the image so that it is normalized from zero to one\n",
    "def normalize_image(image):\n",
    "    min_ = image.min()\n",
    "    max_ = image.max()\n",
    "    eps = 1.0e-7\n",
    "    normalized_image = (image - min_ + eps) / (max_ + eps)\n",
    "    return normalized_image\n",
    "\n",
    "# transform a label image to one hot encoding.\n",
    "# e.g. transform a 2d label image with label ids [1, 2]:\n",
    "# [[0, 0, 1],\n",
    "#  [0, 1, 1],\n",
    "#   0, 2, 2]]\n",
    "# into an image with two channels:\n",
    "# first channel with mask for label 1\n",
    "# [[0, 0, 1],\n",
    "#  [0, 1, 1],\n",
    "#  [0, 0, 0]]\n",
    "# second channel with mask for label 2\n",
    "# [[0, 0, 0],\n",
    "#  [0, 0, 0],\n",
    "#  [0, 1, 1]] \n",
    "# note that we treat zero as background here\n",
    "def one_hot_encoding(labels, n_classes):\n",
    "    target = np.zeros((n_classes,) + labels.shape, dtype=\"float32\")\n",
    "    for chan_id, class_id in enumerate(range(1, n_classes + 1)):\n",
    "        target[chan_id] = labels == class_id\n",
    "    return target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L6Zf2tpXh8Tk"
   },
   "outputs": [],
   "source": [
    "# any PyTorch dataset class should inherit from torch.utils.data.Dataset\n",
    "class MyelinDataset(Dataset):\n",
    "    \"\"\" A PyTorch dataset to provide the images and labels.\"\"\"\n",
    "    def __init__(self, images, labels, patch_shape, transform=None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        assert len(self.images) == len(self.labels)\n",
    "        \n",
    "        # the patch shape is the image size returned by this data loader, e.g. 512x512\n",
    "        self.patch_shape = patch_shape\n",
    "        \n",
    "        # determine the numper of samples and classes from the data\n",
    "        self.n_samples = len(images)\n",
    "        self.n_classes = self.compute_n_classes(self.labels)\n",
    "        \n",
    "        # the transformation applied to the input image, here we just use normalization\n",
    "        self.image_transform = normalize_image\n",
    "        # the transformation applied to the input labels, here we transform the label image into multi-channel binary masks\n",
    "        self.label_transform = partial(one_hot_encoding, n_classes=self.n_classes)\n",
    "        # transformations applied to both images and labels.\n",
    "        # this can for example be used for data augmentation\n",
    "        self.transform = transform\n",
    "    \n",
    "    # compute the number of classes in our labels\n",
    "    def compute_n_classes(self, labels):\n",
    "        # compute all unique values in the label images\n",
    "        unique_label_values = np.unique(np.concatenate([lab.flatten() for lab in labels]))\n",
    "        # the number of classes is the number of unique labels - 1\n",
    "        # (because we don't take into account zero)\n",
    "        return len(unique_label_values) - 1\n",
    "\n",
    "    # get the total number of samples\n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "\n",
    "    # fetch the training sample given its index\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        labels = self.labels[idx]\n",
    "        assert image.shape == labels.shape\n",
    "        \n",
    "        # sample a random patch for this image\n",
    "        start_coordinates = [np.random.randint(0, shape - pshape) for shape, pshape in zip(image.shape, self.patch_shape)]\n",
    "        patch = tuple(slice(start, start + shape) for start, shape in zip(start_coordinates, self.patch_shape))\n",
    "        \n",
    "        # get the image and labels from the patch\n",
    "        input_ = np.asarray(image[patch])\n",
    "        target = np.asarray(labels[patch])\n",
    "        \n",
    "        # apply the transformations\n",
    "        if self.image_transform is not None:\n",
    "            input_ = self.image_transform(input_)\n",
    "        if self.label_transform is not None:\n",
    "            target = self.label_transform(target)\n",
    "        if self.transform is not None:\n",
    "            input_, target = self.transform(input_, target)\n",
    "        \n",
    "        # make sure the input has a channel axis\n",
    "        if input_.ndim == 2:\n",
    "            input_ = input_[None]\n",
    "        \n",
    "        return input_, target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wp6nJdOgvZBl"
   },
   "source": [
    "Now let's load the dataset and visualize it with a simple function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# patch_shape = (1024, 1024)\n",
    "# small patch shape for testing, choose a bigger one in your experiments (e.g. above)\n",
    "patch_shape = (512, 512)\n",
    "train_dataset = MyelinDataset(train_images, train_labels, patch_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_sample_from_dataset(dataset):\n",
    "    idx = np.random.randint(0, len(dataset)) # take a random sample\n",
    "    image, target = train_dataset[idx]\n",
    "    print(image.shape)\n",
    "    print(target.shape)\n",
    "    v = napari.Viewer()\n",
    "    v.add_image(image)\n",
    "    v.add_image(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_sample_from_dataset(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lf7Y_PmU7sQ3"
   },
   "outputs": [],
   "source": [
    "# the unet is copied directly from the webinar exercise\n",
    "class UNet(nn.Module):\n",
    "    \"\"\" UNet implementation\n",
    "    Arguments:\n",
    "      in_channels: number of input channels\n",
    "      out_channels: number of output channels\n",
    "      final_activation: activation applied to the network output\n",
    "    \"\"\"\n",
    "    \n",
    "    # _conv_block and _upsampler are just helper functions to\n",
    "    # construct the model.\n",
    "    # encapsulating them like so also makes it easy to re-use\n",
    "    # the model implementation with different architecture elements\n",
    "    \n",
    "    # Convolutional block for single layer of the decoder / encoder\n",
    "    # we apply to 2d convolutions with relu activation\n",
    "    def _conv_block(self, in_channels, out_channels):\n",
    "        return nn.Sequential(nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "                             nn.ReLU(),\n",
    "                             nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "                             nn.ReLU())       \n",
    "\n",
    "\n",
    "    # upsampling via transposed 2d convolutions\n",
    "    def _upsampler(self, in_channels, out_channels):\n",
    "        return nn.ConvTranspose2d(in_channels, out_channels,\n",
    "                                kernel_size=2, stride=2)\n",
    "    \n",
    "    def __init__(self, in_channels=1, out_channels=1, \n",
    "                 final_activation=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        # the depth (= number of encoder / decoder levels) is\n",
    "        # hard-coded to 4\n",
    "        self.depth = 4\n",
    "\n",
    "        # the final activation must either be None or a Module\n",
    "        if final_activation is not None:\n",
    "            assert isinstance(final_activation, nn.Module), \"Activation must be torch module\"\n",
    "        \n",
    "        # all lists of conv layers (or other nn.Modules with parameters) must be wraped\n",
    "        # itnto a nn.ModuleList\n",
    "        \n",
    "        # modules of the encoder path\n",
    "        self.encoder = nn.ModuleList([self._conv_block(in_channels, 16),\n",
    "                                      self._conv_block(16, 32),\n",
    "                                      self._conv_block(32, 64),\n",
    "                                      self._conv_block(64, 128)])\n",
    "        # the base convolution block\n",
    "        self.base = self._conv_block(128, 256)\n",
    "        # modules of the decoder path\n",
    "        self.decoder = nn.ModuleList([self._conv_block(256, 128),\n",
    "                                      self._conv_block(128, 64),\n",
    "                                      self._conv_block(64, 32),\n",
    "                                      self._conv_block(32, 16)])\n",
    "        \n",
    "        # the pooling layers; we use 2x2 MaxPooling\n",
    "        self.poolers = nn.ModuleList([nn.MaxPool2d(2) for _ in range(self.depth)])\n",
    "        # the upsampling layers\n",
    "        self.upsamplers = nn.ModuleList([self._upsampler(256, 128),\n",
    "                                         self._upsampler(128, 64),\n",
    "                                         self._upsampler(64, 32),\n",
    "                                         self._upsampler(32, 16)])\n",
    "        # output conv and activation\n",
    "        # the output conv is not followed by a non-linearity, because we apply\n",
    "        # activation afterwards\n",
    "        self.out_conv = nn.Conv2d(16, out_channels, 1)\n",
    "        self.activation = final_activation\n",
    "    \n",
    "    def forward(self, input):\n",
    "        x = input\n",
    "        # apply encoder path\n",
    "        encoder_out = []\n",
    "        for level in range(self.depth):\n",
    "            x = self.encoder[level](x)\n",
    "            encoder_out.append(x)\n",
    "            x = self.poolers[level](x)\n",
    "\n",
    "        # apply base\n",
    "        x = self.base(x)\n",
    "        \n",
    "        # apply decoder path\n",
    "        encoder_out = encoder_out[::-1]\n",
    "        for level in range(self.depth):\n",
    "            x = self.upsamplers[level](x)\n",
    "            x = self.decoder[level](torch.cat((x, encoder_out[level]), dim=1))\n",
    "        \n",
    "        # apply output conv and activation (if given)\n",
    "        x = self.out_conv(x)\n",
    "        if self.activation is not None:\n",
    "            x = self.activation(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k4BbxNxVxVuE"
   },
   "outputs": [],
   "source": [
    "# we use the dice coefficient as loss function\n",
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, eps=1e-6):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        \n",
    "    # the dice coefficient of two sets represented as vectors a, b ca be \n",
    "    # computed as (2 *|a b| / (a^2 + b^2))\n",
    "    def forward(self, prediction, target):\n",
    "        assert prediction.shape == target.shape, f\"{prediction.shape}, {target.shape}\"\n",
    "        # compute the dice_score for each channel independently\n",
    "        # Note that the tensor has the shape BATCHES X CHANNELS X WIDTH X HEIGHT\n",
    "        dice_loss = 0.0\n",
    "        n_channels = prediction.shape[1]\n",
    "        for channel_id in range(n_channels):\n",
    "            pred, trgt = prediction[:, channel_id], target[:, channel_id]\n",
    "            intersection = (pred * trgt).sum()\n",
    "            denominator = (pred * pred).sum() + (trgt * trgt).sum()\n",
    "            dice_score = (2 * intersection / denominator.clamp(min=self.eps))\n",
    "            # we use 1 - the dice score as a loss, so that lower values correspond to a better solution\n",
    "            # (as required for a loss function)\n",
    "            # note that a perfect match corresponds to a dice score of 1 and a complete miss to a dice score of 0\n",
    "            dice_loss += 1.0 - dice_score\n",
    "        # normalize the dice loss by the number of channels\n",
    "        return dice_loss / n_channels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Bfq6uCE3yfjo"
   },
   "source": [
    "## Training\n",
    "\n",
    "Implement and run training for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3vHmBksOzpl9"
   },
   "outputs": [],
   "source": [
    "# apply training for one epoch\n",
    "def train(model, loader, optimizer, loss_function,\n",
    "          epoch, log_interval=100, log_image_interval=20, tb_logger=None):\n",
    "\n",
    "    # set the model to train mode\n",
    "    model.train()\n",
    "    # iterate over the batches of this epoch\n",
    "    for batch_id, (x, y) in enumerate(loader):\n",
    "        # move input and target to the active device (either cpu or gpu)\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        \n",
    "        # zero the gradients for this iteration\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # apply model, calculate loss and run backwards pass\n",
    "        prediction = model(x)\n",
    "        loss = loss_function(prediction, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # log to console\n",
    "        if batch_id % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                  epoch, batch_id * len(x),\n",
    "                  len(loader.dataset),\n",
    "                  100. * batch_id / len(loader), loss.item()))\n",
    "\n",
    "       # log to tensorboard\n",
    "        if tb_logger is not None:\n",
    "            step = epoch * len(loader) + batch_id\n",
    "            tb_logger.add_scalar(tag='train_loss', scalar_value=loss.item(), global_step=step)\n",
    "            # check if we log images in this iteration\n",
    "            if step % log_image_interval == 0:\n",
    "                img = img_tensor=x.to('cpu')\n",
    "                tb_logger.add_images(tag='input', img_tensor=img, global_step=step)\n",
    "                tb_logger.add_images(tag='target', img_tensor=y.to('cpu'), global_step=step)\n",
    "                tb_logger.add_images(tag='prediction', img_tensor=prediction.to('cpu').detach(), global_step=step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MMARc1MBzsCT"
   },
   "source": [
    "\n",
    "This time we will use GPU to train faster. Please make sure that your Notebook is running on GPU. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SGJeKzlmvn-A"
   },
   "outputs": [],
   "source": [
    "# check if we have  a gpu\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU is available\")\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    print(\"GPU is not available\")\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6Tai5zj8U6kg"
   },
   "outputs": [],
   "source": [
    "# start a tensorboard writer\n",
    "logger = SummaryWriter('runs/Unet')\n",
    "%tensorboard --logdir runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1RUwWEAFVHLz"
   },
   "outputs": [],
   "source": [
    "# build a default unet with sigmoid activation\n",
    "# to normalize predictions to [0, 1]\n",
    "net = UNet(1, 3, final_activation=nn.Sigmoid())\n",
    "# move the model to GPU\n",
    "net = net.to(device)\n",
    "\n",
    "# create the loader from the training dataset\n",
    "batch_size = 1  # the batch size used for training\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "# TODO create the validation dataset and validation loader\n",
    "\n",
    "# define the loss function and optimizer\n",
    "loss_function = DiceLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=1.0e-4)\n",
    "\n",
    "# TODO: define a metric to be used for validation\n",
    "\n",
    "# train for a number of epochs\n",
    "# during the training you can inspect the \n",
    "# predictions in the tensorboard\n",
    "n_epochs = 25\n",
    "for epoch in range(n_epochs):\n",
    "    # run training for this epoch\n",
    "    train(net, train_loader, optimizer, loss_function, epoch, tb_logger=logger)\n",
    "    step = epoch * len(train_loader.dataset)\n",
    "    # validate\n",
    "    # TODO: implement the validation here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Untitled",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
